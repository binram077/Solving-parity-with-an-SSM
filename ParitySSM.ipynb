{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In a recent video lecture (https://youtu.be/DP454c1K_vQ?t=4841), Professor JÃ¼rgen Schmidhuber claimed that Mamba, a type of State Space Model (SSM), cannot solve the parity problem. This claim sparked my curiosity and led me to investigate a simpler SSM that could potentially solve this problem.\n",
        "# The Parity Problem\n",
        "The parity problem involves a string of 1s and 0s. For each point in the string, we need to output whether the number of 1s encountered up to that point is even or odd.\n",
        "# A Simple SSM Solution\n",
        "I propose a simple SSM that can solve the parity problem using the following formula:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "A &= [\\pi \\cdot i] \\,\n",
        ",\\delta = x \\\n",
        ",S_0 = 1 \\\n",
        ",S_{t+1} = e^{A \\cdot \\delta} \\cdot S_t + 0\n",
        "\\end{aligned}\n",
        "$$\n",
        "This formulation allows the state to flip only when we encounter a 1, effectively solving the parity problem.\n",
        "# Challenges for Complex Mamba\n",
        "While exploring this solution, I identified three reasons why it might be challenging for a complex Mamba model to implement this:\n",
        "\n",
        "Mamba uses addition in its state update, which makes it difficult to preserve the state within normalized bounds without decay, and we don't want decay to take place(if there is continous decay at some point what you entered will be erased).\n",
        "\n",
        "If $\\delta$ is not exactly 1, there will be a bias over time that gradually sways the model until it loses accuracy.\n",
        "\n",
        "Mamba cannot assign a $\\delta$ of zero for an input due to the softplus function in its $\\delta$ calculation, and that means it won't be able to completely ignore the zeroes(which is neccesary for the parity problem).\n",
        "\n",
        "# Proposed Architecture\n",
        "To address these challenges, I developed a new architecture that implements the simple SSM described above. The key insight is that we only need to track the complex angle/phase of the state, as the magnitude/radius is always one (we're moving on the unit circle).\n",
        "\n",
        "The updated formula for this architecture is:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "S_0 = 0 \\text{ (radians/}\\pi\\text{)} \\\n",
        ",S_{t+1} = (S_t + \\text{angle}_t) \\bmod 1 \\\n",
        ",\\text{out1}_t = \\cos(S_t \\cdot \\pi) \\\n",
        ",\\text{out2}_t = \\sin(S_t \\cdot \\pi)\n",
        "\\end{aligned}\n",
        "$$\n",
        "To ensure the model can achieve a state flip when encountering a 1, I divided the unit circle into 100 pieces. The input angle is floored to the nearest division, pushing us forward by 1-100 divisions on the unit circle. To maintain gradient flow, I employed the gradient skipping method from VQ-VAE.\n",
        "\n",
        "So the final formula is:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "S_0 = 0 \\text{ (radians/}\\pi\\text{)} \\\n",
        ",S_{t+1} = (S_t + Round(\\text{angle}_t , Num\\_digits = 2)) \\bmod 1 \\\n",
        ",\\text{out1}_t = \\cos(S_t \\cdot \\pi) \\\n",
        ",\\text{out2}_t = \\sin(S_t \\cdot \\pi)\n",
        "\\end{aligned}\n",
        "$$\n",
        "# Implications and Limitations\n",
        "This architecture provides a flip-flop-like capability for infinite-context-length state manipulation. However, it's important to note that the model cannot view its current state to decide whether to flip it. This means it can't imitate every type of automaton.\n",
        "\n",
        "For the parity problem, we only need the current input (action) to determine the state transition, not the current state. This is why our model can solve the parity problem effectively.\n",
        "\n",
        "While I'm not certain about the full range of tasks this architecture can solve, I'm pleased to report that it generalizes from training on sequence lengths of 100 to testing on infinite sequence lengths for the parity problem."
      ],
      "metadata": {
        "id": "HAedZBEECTE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "3ws1kj7M1hso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wydp3jFgLaI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim, round, tensor\n",
        "\n",
        "pi = torch.acos(torch.zeros(1)).item() * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "VZgeCIx51k__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class parityModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_digits = 2\n",
        "        self.input_multiplier = nn.Parameter(torch.normal(tensor(0.3), tensor(0.1)))\n",
        "        self.W = nn.Parameter(torch.normal(tensor([0.3]*2), tensor([0.1]*2)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        delta = torch.relu(torch.tanh(self.input_multiplier * x))\n",
        "        quantized_delta = delta + (round(delta, decimals = self.n_digits) - delta).detach()\n",
        "        states = torch.cumsum(quantized_delta, dim=-1) % 1\n",
        "        states = states * 2 * pi\n",
        "        angles = torch.cat([torch.cos(states)[:,:,None], torch.sin(states)[:,:,None]], dim = -1)\n",
        "        preds = torch.sigmoid(2*torch.einsum('bsd,d->bs', angles, self.W))\n",
        "        return preds"
      ],
      "metadata": {
        "id": "ql5WSVnygq4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = parityModel()"
      ],
      "metadata": {
        "id": "UTNd_yekn-h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = p(torch.ones((2,15)))\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWDt5Z2eoB4n",
        "outputId": "d2c053f7-53ba-47d5-f494-9ce5f16275df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5684, 0.2825, 0.6508, 0.5822, 0.2804, 0.6402, 0.5957, 0.2790, 0.6289,\n",
            "         0.6086, 0.2784, 0.6169, 0.6209, 0.2785, 0.6044],\n",
            "        [0.5684, 0.2825, 0.6508, 0.5822, 0.2804, 0.6402, 0.5957, 0.2790, 0.6289,\n",
            "         0.6086, 0.2784, 0.6169, 0.6209, 0.2785, 0.6044]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data generation"
      ],
      "metadata": {
        "id": "NftRaOKxSCzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(batch_size, seq_len, precentage_of_zeroes = 0.5):\n",
        "    X = (torch.rand((batch_size, seq_len)) > precentage_of_zeroes)\n",
        "    Y = X[:,0].unsqueeze(-1)\n",
        "    for i in range(1,X.shape[-1]):\n",
        "        Y = torch.cat([Y, torch.logical_xor(Y[:,-1].unsqueeze(-1), X[:,i].unsqueeze(-1))], dim = -1)\n",
        "    return X.float(), Y.float()"
      ],
      "metadata": {
        "id": "10fLAbWcKfmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_batch(3,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePeqnEKrP-Tu",
        "outputId": "e2f8b4bf-3d6e-4865-c2af-35afd71645df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 0., 0., 0.],\n",
              "         [1., 0., 1., 0., 0.],\n",
              "         [0., 1., 0., 1., 0.]]),\n",
              " tensor([[1., 0., 0., 0., 0.],\n",
              "         [1., 1., 0., 0., 0.],\n",
              "         [0., 1., 1., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training loop"
      ],
      "metadata": {
        "id": "PA7f6HrjSIHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(num_epochs, model, optimizer, criterion, batch_size, seq_len):\n",
        "    for i in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        X, Y = generate_batch(batch_size, seq_len)\n",
        "        preds = model(X)\n",
        "\n",
        "        loss = criterion(Y, preds)\n",
        "\n",
        "        if i % 100 == 99:\n",
        "\n",
        "            X_test, Y_test = generate_batch(batch_size, seq_len)\n",
        "            test_preds = model(X_test)\n",
        "\n",
        "            accuracy = ((test_preds > 0.5).float() == Y_test).float().mean()\n",
        "\n",
        "            print(f'accuracy: {accuracy}, loss: {loss}')\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "v4qxRkQFSE1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = parityModel()\n",
        "\n",
        "optimizer = optim.Adam(p.parameters(), lr = 1e-3)\n",
        "\n",
        "training_loop(10000, p, optimizer, nn.MSELoss(), 64, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqVF9UIaT9E_",
        "outputId": "f56491c0-e346-4bcf-d299-3431222f9eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.5284374952316284, loss: 0.25648486614227295\n",
            "accuracy: 0.5262500047683716, loss: 0.2531069219112396\n",
            "accuracy: 0.5254687666893005, loss: 0.2507232129573822\n",
            "accuracy: 0.5310937762260437, loss: 0.250151127576828\n",
            "accuracy: 0.5298437476158142, loss: 0.250132292509079\n",
            "accuracy: 0.4921875, loss: 0.24996539950370789\n",
            "accuracy: 0.5029687285423279, loss: 0.24997840821743011\n",
            "accuracy: 0.5159375071525574, loss: 0.24989449977874756\n",
            "accuracy: 0.5107812285423279, loss: 0.2498777210712433\n",
            "accuracy: 0.4925000071525574, loss: 0.25000011920928955\n",
            "accuracy: 0.5218750238418579, loss: 0.24993100762367249\n",
            "accuracy: 0.4868749976158142, loss: 0.2500340938568115\n",
            "accuracy: 0.514843761920929, loss: 0.24987514317035675\n",
            "accuracy: 0.5087500214576721, loss: 0.25004783272743225\n",
            "accuracy: 0.48531249165534973, loss: 0.2500492036342621\n",
            "accuracy: 0.49031248688697815, loss: 0.2498769909143448\n",
            "accuracy: 0.48515623807907104, loss: 0.2498980313539505\n",
            "accuracy: 0.4778124988079071, loss: 0.2500070631504059\n",
            "accuracy: 0.5239062309265137, loss: 0.24997378885746002\n",
            "accuracy: 0.5170312523841858, loss: 0.25003185868263245\n",
            "accuracy: 0.5185937285423279, loss: 0.2499903440475464\n",
            "accuracy: 0.4950000047683716, loss: 0.25012242794036865\n",
            "accuracy: 0.4856249988079071, loss: 0.24999214708805084\n",
            "accuracy: 0.4845312535762787, loss: 0.2500162422657013\n",
            "accuracy: 0.49437499046325684, loss: 0.24993856251239777\n",
            "accuracy: 0.49515625834465027, loss: 0.24995635449886322\n",
            "accuracy: 0.49921876192092896, loss: 0.2498641163110733\n",
            "accuracy: 0.5078125, loss: 0.25009456276893616\n",
            "accuracy: 0.5045312643051147, loss: 0.25012800097465515\n",
            "accuracy: 0.5303124785423279, loss: 0.2501174807548523\n",
            "accuracy: 0.4937500059604645, loss: 0.24985796213150024\n",
            "accuracy: 0.48906248807907104, loss: 0.25011953711509705\n",
            "accuracy: 0.4699999988079071, loss: 0.2500081956386566\n",
            "accuracy: 0.47968751192092896, loss: 0.24997180700302124\n",
            "accuracy: 0.48625001311302185, loss: 0.24981163442134857\n",
            "accuracy: 0.51171875, loss: 0.2500391900539398\n",
            "accuracy: 0.49515625834465027, loss: 0.24991288781166077\n",
            "accuracy: 0.5093749761581421, loss: 0.2500445544719696\n",
            "accuracy: 0.5159375071525574, loss: 0.24988482892513275\n",
            "accuracy: 0.6035937666893005, loss: 0.24980469048023224\n",
            "accuracy: 0.41453126072883606, loss: 0.24994127452373505\n",
            "accuracy: 0.6042187213897705, loss: 0.2500012218952179\n",
            "accuracy: 0.6112499833106995, loss: 0.24981918931007385\n",
            "accuracy: 0.40671876072883606, loss: 0.24984939396381378\n",
            "accuracy: 0.4867187440395355, loss: 0.249781996011734\n",
            "accuracy: 0.4790624976158142, loss: 0.24991199374198914\n",
            "accuracy: 0.5096874833106995, loss: 0.2497563362121582\n",
            "accuracy: 0.5032812356948853, loss: 0.24983932077884674\n",
            "accuracy: 0.5179687738418579, loss: 0.24972787499427795\n",
            "accuracy: 0.49828124046325684, loss: 0.2496786266565323\n",
            "accuracy: 0.47453126311302185, loss: 0.2500135600566864\n",
            "accuracy: 0.5489062666893005, loss: 0.24890264868736267\n",
            "accuracy: 0.0, loss: 0.25531837344169617\n",
            "accuracy: 1.0, loss: 0.1470649093389511\n",
            "accuracy: 0.7885937690734863, loss: 0.13958775997161865\n",
            "accuracy: 0.8042187690734863, loss: 0.12985959649085999\n",
            "accuracy: 0.8149999976158142, loss: 0.12468718737363815\n",
            "accuracy: 0.8020312786102295, loss: 0.1340770572423935\n",
            "accuracy: 0.8149999976158142, loss: 0.14359663426876068\n",
            "accuracy: 1.0, loss: 0.04096219688653946\n",
            "accuracy: 1.0, loss: 0.035790350288152695\n",
            "accuracy: 1.0, loss: 0.03150214999914169\n",
            "accuracy: 1.0, loss: 0.02799886465072632\n",
            "accuracy: 0.7828124761581421, loss: 0.13377638161182404\n",
            "accuracy: 1.0, loss: 0.022493047639727592\n",
            "accuracy: 1.0, loss: 0.020323507487773895\n",
            "accuracy: 1.0, loss: 0.018438704311847687\n",
            "accuracy: 0.8082812428474426, loss: 0.13752205669879913\n",
            "accuracy: 0.7829687595367432, loss: 0.14470326900482178\n",
            "accuracy: 1.0, loss: 0.014080374501645565\n",
            "accuracy: 1.0, loss: 0.012966446578502655\n",
            "accuracy: 0.7989062666893005, loss: 0.13833189010620117\n",
            "accuracy: 1.0, loss: 0.01102867629379034\n",
            "accuracy: 1.0, loss: 0.0102190300822258\n",
            "accuracy: 1.0, loss: 0.009483084082603455\n",
            "accuracy: 1.0, loss: 0.00881132110953331\n",
            "accuracy: 1.0, loss: 0.00821029581129551\n",
            "accuracy: 1.0, loss: 0.007655724883079529\n",
            "accuracy: 1.0, loss: 0.00715015409514308\n",
            "accuracy: 1.0, loss: 0.006688988767564297\n",
            "accuracy: 1.0, loss: 0.0062624732963740826\n",
            "accuracy: 1.0, loss: 0.005876440554857254\n",
            "accuracy: 1.0, loss: 0.005516772158443928\n",
            "accuracy: 1.0, loss: 0.00518224760890007\n",
            "accuracy: 1.0, loss: 0.004877305589616299\n",
            "accuracy: 1.0, loss: 0.004594809841364622\n",
            "accuracy: 1.0, loss: 0.004328705836087465\n",
            "accuracy: 1.0, loss: 0.004083066247403622\n",
            "accuracy: 1.0, loss: 0.0038536018691956997\n",
            "accuracy: 1.0, loss: 0.0036431506741791964\n",
            "accuracy: 1.0, loss: 0.0034466765355318785\n",
            "accuracy: 1.0, loss: 0.0032576131634414196\n",
            "accuracy: 1.0, loss: 0.0030815217178314924\n",
            "accuracy: 1.0, loss: 0.0029249428771436214\n",
            "accuracy: 1.0, loss: 0.002767779165878892\n",
            "accuracy: 1.0, loss: 0.0026275240816175938\n",
            "accuracy: 1.0, loss: 0.0024992702528834343\n",
            "accuracy: 1.0, loss: 0.002369946101680398\n",
            "accuracy: 0.7724999785423279, loss: 0.17121104896068573\n",
            "accuracy: 1.0, loss: 0.002140848897397518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking performance on longer sequences"
      ],
      "metadata": {
        "id": "Vx5aE_n51rtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, Y_test = generate_batch(64, 40000)\n",
        "test_preds = p(X_test)\n",
        "\n",
        "accuracy = ((test_preds > 0.5).float() == Y_test).float().mean()\n",
        "\n",
        "print(f'accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hTbkg4KXKUr",
        "outputId": "79041c65-3150-4a09-99e7-57f6db7f3e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the delta of 1 (meaning how much a input of 1 push us forward on the circle unit) and the result is as expected exactly 0.5 ."
      ],
      "metadata": {
        "id": "hhoLNsSy1zhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta = torch.relu(torch.tanh(p.input_multiplier * 1.0))\n",
        "quantized_delta = delta + (round(delta, decimals = 2) - delta).detach()\n",
        "print(quantized_delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG4-KL5UYJGj",
        "outputId": "a0f32b7b-a0b3-47f8-a20f-901f53ac99f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5000, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}